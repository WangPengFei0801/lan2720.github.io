<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Lan&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="Lan's Blog">
<meta property="og:url" content="http://lan2720.github.io/index.html">
<meta property="og:site_name" content="Lan's Blog">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Lan's Blog">
<meta name="twitter:description">
  
    <link rel="alternative" href="/atom.xml" title="Lan&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <script src="http://libs.baidu.com/jquery/1.9.0/jquery.js"></script>
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img lazy-src="http://cdldy.img44.wal8.com/img44/517242_20150506085541/143087388199.png" class="js-avatar">
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Lan</a></h1>
		</hgroup>

		
		<p class="header-subtitle">属性GEEK, 冷静思考</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						<li>友情链接</li>
						
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
							<li><a href="/about">ABOUT ME</a></li>
				        
							<li><a href="/深度学习资源">深度学习资源</a></li>
				        
							<li><a href="/机器学习资源">机器学习资源</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/lan2720" title="github">github</a>
					        
								<a class="zhihu" target="_blank" href="http://www.zhihu.com/people/loafer-527" title="zhihu">zhihu</a>
					        
								<a class="douban" target="_blank" href="http://www.douban.com/people/57762260/" title="douban">douban</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/deeplearningtutorials/" style="font-size: 15px;">deeplearningtutorials</a><a href="/tags/java/" style="font-size: 15px;">java</a><a href="/tags/julyedu/" style="font-size: 10px;">julyedu</a><a href="/tags/life/" style="font-size: 10px;">life</a><a href="/tags/machinelearning/" style="font-size: 10px;">machinelearning</a><a href="/tags/neuralnetworksanddeeplearning/" style="font-size: 15px;">neuralnetworksanddeeplearning</a><a href="/tags/python/" style="font-size: 10px;">python</a><a href="/tags/ufldl/" style="font-size: 10px;">ufldl</a><a href="/tags/动态规划/" style="font-size: 10px;">动态规划</a><a href="/tags/学习笔记/" style="font-size: 20px;">学习笔记</a><a href="/tags/算法/" style="font-size: 10px;">算法</a><a href="/tags/自动寻参/" style="font-size: 10px;">自动寻参</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://summer-last.blogbus.com/">陈小醒</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://lucumr.pocoo.org/">Armin Ronacher</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://www.liaoxuefeng.com/">廖雪峰</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://www.lyonwj.com/">William Lyon</a>
			        
			        </div>
				</section>
				

				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Lan</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="http://cdldy.img44.wal8.com/img44/517242_20150506085541/143087388199.png" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">Lan</h1>
			</hgroup>
			
			<p class="header-subtitle">属性GEEK, 冷静思考</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
					<li><a href="/about">ABOUT ME</a></li>
		        
					<li><a href="/深度学习资源">深度学习资源</a></li>
		        
					<li><a href="/机器学习资源">机器学习资源</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/lan2720" title="github">github</a>
			        
						<a class="zhihu" target="_blank" href="http://www.zhihu.com/people/loafer-527" title="zhihu">zhihu</a>
			        
						<a class="douban" target="_blank" href="http://www.douban.com/people/57762260/" title="douban">douban</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap">
  
    <article id="post-Gaussian-Process代码理解" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/07/30/Gaussian-Process代码理解/" class="article-date">
  	<time datetime="2015-07-30T12:03:10.000Z" itemprop="datePublished">2015-07-30</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/30/Gaussian-Process代码理解/">Gaussian Process代码理解</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>今天看了大神Nando de Freitas在UBC讲的machine learning 2013年春季课程，关于高斯过程的视频，对GP有了初步的理解。<br>课上他给出了一段GP的代码。看见python代码就激动肯定是一种病，哈哈。<br>逐步分析一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This is the true unknown function we are trying to approximate</span></span><br><span class="line">f = <span class="keyword">lambda</span> x: np.sin(<span class="number">0.9</span>*x).flatten()</span><br></pre></td></tr></table></figure>
<p>这是我们要不断去近似的一个方程。对于深度学习的自动寻参而言，我们给定几组参数组合，然后得到这几组参数对应的训练效果，那么可以根据这几组已知的结果，去预测在整个参数空间范围内，参数组合会有怎样一个训练结果趋势。这个结果趋势就是通过GP模拟出的。<br>其中隐含了一个信息：所以可能的参数组合他们所得出的训练结果真实值。但是这个真实值我们是得不到的，如果得到了我们就不用费劲，直接在这些结果中找到训练结果最好的那组参数就万事大吉了。但是，事与愿违，既然不能得到这样一个潜在的真实值，我们只能通过贝爷的方法去模拟出一个大致接近真实值的值。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define the kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kernel</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="string">""" GP squared exponential kernel """</span></span><br><span class="line">    kernelParameter = <span class="number">0.1</span></span><br><span class="line">    sqdist = np.sum(a**<span class="number">2</span>,<span class="number">1</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>) + np.sum(b**<span class="number">2</span>,<span class="number">1</span>) - <span class="number">2</span>*np.dot(a, b.T)</span><br><span class="line">    <span class="keyword">return</span> np.exp(-.<span class="number">5</span> * (<span class="number">1</span>/kernelParameter) * sqdist)</span><br></pre></td></tr></table></figure></p>
<p>这里定义了一个核方法。这个核方法是用来计算K的，K就是两个变量a，b的协方差矩阵。<br>核方法有很多，对应到不同领域又有处理文本的，处理图像音频的核方程。这里只是简单的拿一个核作为例子进行讲解。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">N = <span class="number">10</span>         <span class="comment"># number of training points.</span></span><br><span class="line">n = <span class="number">50</span>         <span class="comment"># number of test points.</span></span><br><span class="line">s = <span class="number">0.00005</span>    <span class="comment"># noise variance.</span></span><br></pre></td></tr></table></figure>
<p>这里给出10组训练点。最后要预测50个测试点。并且在y值上加上噪音。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Sample some input points and noisy versions of the function evaluated at</span></span><br><span class="line"><span class="comment"># these points. </span></span><br><span class="line">X = np.random.uniform(-<span class="number">5</span>, <span class="number">5</span>, size=(N,<span class="number">1</span>))</span><br><span class="line">y = f(X) + s*np.random.randn(N)</span><br></pre></td></tr></table></figure>
<p>生成训练点的坐标。训练点得到的观测值也可能是不准确的，所以要加上一些噪音。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">K = kernel(X, X)</span><br><span class="line">L = np.linalg.cholesky(K + s*np.eye(N))</span><br></pre></td></tr></table></figure>
<p>生成训练点的协方差矩阵K和cholesky分解后的L。<br>K和L存在如下关系，近似于开方了。<br>$K = L\cdot L^T$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># points we're going to make predictions at.</span></span><br><span class="line">Xtest = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, n).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>生成测试点的坐标，而不知道这些测试点的y值，所以通过GP来预测这些y值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># compute the mean at our test points.</span></span><br><span class="line">Lk = np.linalg.solve(L, kernel(X, Xtest))</span><br><span class="line">mu = np.dot(Lk.T, np.linalg.solve(L, y))</span><br></pre></td></tr></table></figure>
<p>计算测试点的y值的均值（按公式）。<br><img src="http://ww1.sinaimg.cn/large/901f9a6fgw1eukvlj5amrj20e603owel.jpg" alt=""><br><img src="http://ww2.sinaimg.cn/large/901f9a6fgw1eukwkdcpo5j206b01m743.jpg" alt=""><br>将上式中$K<em>y$带换成$L\cdot L^T$。<br>得到$\mu</em>\star=k^T<em>\star L^{-T}L^{-1}y$<br>进一步将$k^T</em>\star L^{-T}$合并，得到$\mu<em>\star=(L^{-1}k</em>\star)^T L^{-1}y$<br>其中$L^{-1}k_\star = solve(L, k)$，$L^{-1}y = solve(L, y)$<br>因此就得到上面两行代码的结果。</p>
<p><img src="http://ww2.sinaimg.cn/large/901f9a6fgw1eukv2actpwj20j704hmxh.jpg" alt="first correct"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># compute the variance at our test points.</span></span><br><span class="line">K_ = kernel(Xtest, Xtest)</span><br><span class="line">s2 = np.diag(K_) - np.sum(Lk**<span class="number">2</span>, axis=<span class="number">0</span>)</span><br><span class="line">s = np.sqrt(s2)</span><br></pre></td></tr></table></figure>
<p>计算测试点的变动范围$\sigma$。<br>K<em>表示的是$K</em> {\star\star}$矩阵。<br>(还没弄清楚)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PLOTS:</span></span><br><span class="line">pl.figure(<span class="number">1</span>)</span><br><span class="line">pl.clf()</span><br><span class="line">pl.plot(X, y, <span class="string">'r+'</span>, ms=<span class="number">20</span>)</span><br><span class="line">pl.plot(Xtest, f(Xtest), <span class="string">'b-'</span>)</span><br></pre></td></tr></table></figure>
<p>画出测试点和测试点的真实y值（f(Xtest)）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pl.plot(Xtest, mu, <span class="string">'r--'</span>, lw=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>画测试点的均值（预测y值）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># draw samples from the prior at our test points.</span></span><br><span class="line">L = np.linalg.cholesky(K_ + <span class="number">1e-6</span>*np.eye(n))</span><br><span class="line">f_prior = np.dot(L, np.random.normal(size=(n,<span class="number">10</span>)))</span><br><span class="line">pl.figure(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>画出测试点的先验值。<br>因为$y^i \sim N(0, K)$，所以$y<em>{prior}=0 + N(0, I)\cdot L</em>{\star\star}$<br>从而得到了先验值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># draw samples from the posterior at our test points.</span></span><br><span class="line">L = np.linalg.cholesky(K_ + <span class="number">1e-6</span>*np.eye(n) - np.dot(Lk.T, Lk))</span><br><span class="line">f_post = mu.reshape(-<span class="number">1</span>,<span class="number">1</span>) + np.dot(L, np.random.normal(size=(n,<span class="number">10</span>)))</span><br><span class="line">pl.figure(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>得到测试点的后验值。<br>$f_{post} = \mu + N(0, I)\cdot L$<br>（这里的$L$还没搞清楚）</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machinelearning/">machinelearning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/自动寻参/">自动寻参</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
    <article id="post-softmax-regression-vs-logistic-regression" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/07/23/softmax-regression-vs-logistic-regression/" class="article-date">
  	<time datetime="2015-07-23T13:52:36.000Z" itemprop="datePublished">2015-07-23</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/23/softmax-regression-vs-logistic-regression/">softmax regression vs logistic regression</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="基础知识">基础知识</h2><p>logistic regression是个二分类问题。比如，预测病人的肿瘤是恶性（malignant）还是良性（benign）的情况。<br>sofxmax　regression是个多分类问题，类标签$y$可以取两个以上的值。诸如MNIST手写数字分类，辨识10个不同的单个数字。</p>
<h2 id="什么时候用哪个">什么时候用哪个</h2><p>一开始我也很疑惑什么时候用logistic regression什么时候又该用sofxmax regression呢。<a href="http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92#Softmax_.E5.9B.9E.E5.BD.92_vs._k_.E4.B8.AA.E4.BA.8C.E5.85.83.E5.88.86.E7.B1.BB.E5.99.A8">ufldl</a>给出了一个很简单的方法。</p>
<blockquote>
<p>如果你在开发一个音乐分类的应用，需要对k种类型的音乐进行识别，那么是选择使用 softmax 分类器呢，还是使用 logistic 回归算法建立 k 个独立的二元分类器呢？<br>这一选择取决于你的类别之间是否互斥，例如，如果你有四个类别的音乐，分别为：古典音乐、乡村音乐、摇滚乐和爵士乐，那么你可以假设每个训练样本只会被打上一个标签（即：一首歌只能属于这四种音乐类型的其中一种），此时你应该使用类别数 k = 4 的softmax回归。（如果在你的数据集中，有的歌曲不属于以上四类的其中任何一类，那么你可以添加一个“其他类”，并将类别数 k 设为5。）<br>如果你的四个类别如下：人声音乐、舞曲、影视原声、流行歌曲，那么这些类别之间并不是互斥的。例如：一首歌曲可以来源于影视原声，同时也包含人声 。这种情况下，使用4个二分类的 logistic 回归分类器更为合适。这样，对于每个新的音乐作品 ，我们的算法可以分别判断它是否属于各个类别。</p>
</blockquote>
      
    </div>
    
    <div class="article-info article-info-index">
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ufldl/">ufldl</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/学习笔记/">学习笔记</a></li></ul>
	</div>

      

      
        <p class="article-more-link">
          <a  href="/2015/07/23/softmax-regression-vs-logistic-regression/#more">more >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
    <article id="post-用matplotlib可视化来理解autoencoder中的sparse-penalty" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/07/23/用matplotlib可视化来理解autoencoder中的sparse-penalty/" class="article-date">
  	<time datetime="2015-07-23T13:48:50.000Z" itemprop="datePublished">2015-07-23</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/23/用matplotlib可视化来理解autoencoder中的sparse-penalty/">用matplotlib可视化来理解autoencoder中的sparse penalty</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>最近在看<a href="http://deeplearning.net/tutorial/dA.html#daa">Deep Learning Tutorials-Denoising Autoencoders</a>的内容，整个程序全部用theano和numpy写的，思路特别清晰。但是对于sparsity的限制没有感性的认识，一直觉得很玄幻。<br>今天就改了一下它的<a href="https://github.com/lisa-lab/DeepLearningTutorials/blob/master/code/dA.py">源码</a>，用matplotlib将hidden layer每个neuron输出的activation值用散点图的方式绘制出来，通过调节sparse_penalty参数进行对比。<br><img src="http://ww2.sinaimg.cn/large/901f9a6fgw1eucn84hf8qj20mk0h0jxm.jpg" alt="sparse 0.01"><br>图1：当sparse限制在0.01时<br>
      
    </div>
    
    <div class="article-info article-info-index">
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearningtutorials/">deeplearningtutorials</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/学习笔记/">学习笔记</a></li></ul>
	</div>

      

      
        <p class="article-more-link">
          <a  href="/2015/07/23/用matplotlib可视化来理解autoencoder中的sparse-penalty/#more">more >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
    <article id="post-初识Learning-Rate-Schedule问题" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/07/21/初识Learning-Rate-Schedule问题/" class="article-date">
  	<time datetime="2015-07-21T13:34:03.000Z" itemprop="datePublished">2015-07-21</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/21/初识Learning-Rate-Schedule问题/">初识Learning Rate Schedule问题</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="背景">背景</h2><p>首先，上个图来看看。<br><img src="http://ww2.sinaimg.cn/large/901f9a6fgw1eua62ghcgvj20mj0g875y.jpg" alt="diffrenet learning rate compare"><br>
      
    </div>
    
    <div class="article-info article-info-index">
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/neuralnetworksanddeeplearning/">neuralnetworksanddeeplearning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/学习笔记/">学习笔记</a></li></ul>
	</div>

      

      
        <p class="article-more-link">
          <a  href="/2015/07/21/初识Learning-Rate-Schedule问题/#more">more >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
    <article id="post-logistic-sgd代码分析之Early-Stopping" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/07/15/logistic-sgd代码分析之Early-Stopping/" class="article-date">
  	<time datetime="2015-07-15T06:44:47.000Z" itemprop="datePublished">2015-07-15</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/15/logistic-sgd代码分析之Early-Stopping/">logistic_sgd代码分析之Early Stopping</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>暑期实习带我正式迈上了Deep Learning的道路，虽然DL目前来说“坑多路险”，还是感谢geetest的黄老板领我“入坑”。至少这半个月以来看了很多，学了很多，加入了一个新的大家庭。从刚开始的痛苦挣扎到思路逐渐清晰，收获还是不小的。<br>这篇是我学习<a href="http://deeplearning.net/tutorial/logreg.html">Deep Learning Tutorials-Logistic Regression</a>时对代码的理解，如果偏颇请多指正。</p>
<h2 id="Train_Model-Early_Stopping">Train Model-Early Stopping</h2><p>这一部分代码的重点是理解<a href="http://deeplearning.net/tutorial/gettingstarted.html#opt-early-stopping">Early-Stopping</a>的机制。</p>
<blockquote>
<p>Talk is cheap, show me your code.</p>
</blockquote>
<p>上代码》》》<br>
      
    </div>
    
    <div class="article-info article-info-index">
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearningtutorials/">deeplearningtutorials</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/学习笔记/">学习笔记</a></li></ul>
	</div>

      

      
        <p class="article-more-link">
          <a  href="/2015/07/15/logistic-sgd代码分析之Early-Stopping/#more">more >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
    <article id="post-对Network类的代码分析" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/07/13/对Network类的代码分析/" class="article-date">
  	<time datetime="2015-07-13T05:53:05.000Z" itemprop="datePublished">2015-07-13</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/13/对Network类的代码分析/">对Network类的代码分析</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Neural Networks and Deep Learning 第一章学习笔记</p>
<p>感兴趣的请移步<a href="http://neuralnetworksanddeeplearning.com/chap1.html">Neural Networks and Deep Learning - Chapter 1</a></p>
<h2 id="SGD代码解析">SGD代码解析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">SGD</span><span class="params">(self, training_data, epochs, mini_batch_size, eta,</span><br><span class="line">            test_data=None)</span>:</span></span><br><span class="line">        <span class="string">"""Train the neural network using mini-batch stochastic</span><br><span class="line">        gradient descent.  The "training_data" is a list of tuples</span><br><span class="line">        "(x, y)" representing the training inputs and the desired</span><br><span class="line">        outputs.  The other non-optional parameters are</span><br><span class="line">        self-explanatory.  If "test_data" is provided then the</span><br><span class="line">        network will be evaluated against the test data after each</span><br><span class="line">        epoch, and partial progress printed out.  This is useful for</span><br><span class="line">        tracking progress, but slows things down substantially."""</span></span><br><span class="line">        <span class="keyword">if</span> test_data: n_test = len(test_data)</span><br><span class="line">        n = len(training_data)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> xrange(epochs):</span><br><span class="line">            random.shuffle(training_data)</span><br><span class="line">            mini_batches = [</span><br><span class="line">                training_data[k:k+mini_batch_size]</span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> xrange(<span class="number">0</span>, n, mini_batch_size)]</span><br><span class="line">            <span class="keyword">for</span> mini_batch <span class="keyword">in</span> mini_batches:</span><br><span class="line">                self.update_mini_batch(mini_batch, eta)</span><br><span class="line">            <span class="keyword">if</span> test_data:</span><br><span class="line">                <span class="keyword">print</span> <span class="string">"Epoch &#123;0&#125;: &#123;1&#125; / &#123;2&#125;"</span>.format(</span><br><span class="line">                    j, self.evaluate(test_data), n_test)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">print</span> <span class="string">"Epoch &#123;0&#125; complete"</span>.format(j)</span><br></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/neuralnetworksanddeeplearning/">neuralnetworksanddeeplearning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/学习笔记/">学习笔记</a></li></ul>
	</div>

      

      
        <p class="article-more-link">
          <a  href="/2015/07/13/对Network类的代码分析/#more">more >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
    <article id="post-Java访问权限" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/06/14/Java访问权限/" class="article-date">
  	<time datetime="2015-06-14T11:05:18.000Z" itemprop="datePublished">2015-06-14</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/06/14/Java访问权限/">Java访问权限</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="权限的基本介绍">权限的基本介绍</h2><h3 id="public">public</h3><h4 id="类">类</h4><p>当两个类不在同一个包中，public权限就显示出作用了。<br>如果一个类不是public的话，<code>外部包</code>无法对这个类进行访问。</p>
<h4 id="成员变量和函数">成员变量和函数</h4><p>如果想在包的外部调用某一个类的成员变量或者成员函数，那么这个成员必须是public，也就是必须是外部包可见的才能被访问，否则无法访问该成员。</p>
      
    </div>
    
    <div class="article-info article-info-index">
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java/">java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/学习笔记/">学习笔记</a></li></ul>
	</div>

      

      
        <p class="article-more-link">
          <a  href="/2015/06/14/Java访问权限/#more">more >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
    <article id="post-Java中的package" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/06/14/Java中的package/" class="article-date">
  	<time datetime="2015-06-13T16:09:05.000Z" itemprop="datePublished">2015-06-14</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/06/14/Java中的package/">Java中的package</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="什么是Java当中的软件包?">什么是Java当中的软件包?</h2><p>所谓的软件包<br>:    就是把类放在不同的文件夹下</p>
<p>相当于我们平时使用电脑时，有两个同名的文件，但是这两个文件我们都想保存，那么放在不同名的文件夹下，就可以了。对于Java软件包，使用的是同一个原理。</p>
<p>同时，可以理解为java的软件包<br>:    提供了命名空间</p>
<p>即规定了两个类可以重名，但是是两个不同的空间内可以重名。</p>
      
    </div>
    
    <div class="article-info article-info-index">
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java/">java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/学习笔记/">学习笔记</a></li></ul>
	</div>

      

      
        <p class="article-more-link">
          <a  href="/2015/06/14/Java中的package/#more">more >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
    <article id="post-由“哪些类型的值可以做python-dict的key”所引发的血案" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/05/30/由“哪些类型的值可以做python-dict的key”所引发的血案/" class="article-date">
  	<time datetime="2015-05-30T15:42:24.000Z" itemprop="datePublished">2015-05-30</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/05/30/由“哪些类型的值可以做python-dict的key”所引发的血案/">由“哪些类型的值可以做python dict的key”所引发的血案</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>今天遇到了这么一个问题，在C站的forum里小争论了一下</p>
<blockquote>
<p>list/dict/tuple/0/set([])/str中哪些类型能作为dict的key？</p>
</blockquote>
<p>平常较常用的dict的key值类型就是int啊，string啊，float啊，以前真没思考过这个问题，不过现在想来还是有点意思。</p>
<h2 id="什么是hashable？">什么是hashable？</h2><p>请看官方对hashable给出的<a href="https://docs.python.org/2.7/glossary.html#term-hashable">解释</a><br>
      
    </div>
    
    <div class="article-info article-info-index">
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li></ul>
	</div>

      

      
        <p class="article-more-link">
          <a  href="/2015/05/30/由“哪些类型的值可以做python-dict的key”所引发的血案/#more">more >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
    <article id="post-最长公共子序列的求解" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/05/08/最长公共子序列的求解/" class="article-date">
  	<time datetime="2015-05-08T08:52:31.000Z" itemprop="datePublished">2015-05-08</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/05/08/最长公共子序列的求解/">最长公共子序列的求解</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="有何用处">有何用处</h2><p>我习惯在学习一个新事物前想想这玩意在实际生活中有什么用，这样既能方便今后工作中遇到相似情况时快速联想到解决方案，又能在整个学习过程中保持激情——入门时遇到困难阻力是经常有的事，但是有实际应用价值的东西，大家往往少了些畏难情绪，很愿意花时间去钻研。<br>最长公共子序列有两大<strong>意义</strong>：</p>
<ul>
<li>广泛的应用在图形相似处理、媒体流的相似比较、计算生物学方面。生物学家常常利用该算法进行基因序列比对，由此推测序列的结构、功能和演化过程。</li>
</ul>
<blockquote>
<p>基因序列比对略显扯淡了，一般情况下很难接触到这个方面的研究</p>
</blockquote>
<ul>
<li>可以描述两段文字之间的“相似度”，即它们的雷同程度，从而能够用来辨别抄袭。另一方面，对一段文字进行修改之后，计算改动前后文字的最长公共子序列，将除此子序列外的部分提取出来，这种方法判断修改的部分，往往十分准确。简而言之，百度知道、百度百科都用得上。</li>
</ul>
      
    </div>
    
    <div class="article-info article-info-index">
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/julyedu/">julyedu</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/动态规划/">动态规划</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/算法/">算法</a></li></ul>
	</div>

      

      
        <p class="article-more-link">
          <a  href="/2015/05/08/最长公共子序列的求解/#more">more >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2015 Lan
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/mobile.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>





<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>